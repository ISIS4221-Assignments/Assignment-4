{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739aa386",
   "metadata": {},
   "source": [
    "# 1. Downloading the Dataset\n",
    "\n",
    "In this section, the literary dataset used throughout the notebook is downloaded. It consists of several classic books by authors such as Jane Austen, Charles Dickens, and Mark Twain. These texts will serve as the foundation for building word embeddings and training classification models in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d73aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dictionary maps short identifiers of classic English literature books \n",
    "to their corresponding raw text file URLs from Project Gutenberg. \n",
    "\n",
    "The keys follow the pattern: <author_lastname>_<short_title>.\n",
    "The values are direct links to the plain text (.txt) versions of the books.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "books_urls = {\n",
    "    \"austen_pride\": \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\",\n",
    "    \"austen_emma\": \"https://www.gutenberg.org/cache/epub/158/pg158.txt\",\n",
    "    \"austen_sense\": \"https://www.gutenberg.org/cache/epub/161/pg161.txt\",\n",
    "\n",
    "    \"dickens_two_cities\": \"https://www.gutenberg.org/cache/epub/98/pg98.txt\",\n",
    "    \"dickens_expectations\": \"https://www.gutenberg.org/cache/epub/1400/pg1400.txt\",\n",
    "    \"dickens_twist\": \"https://www.gutenberg.org/cache/epub/730/pg730.txt\",\n",
    "\n",
    "    \"twain_tom\": \"https://www.gutenberg.org/cache/epub/74/pg74.txt\",\n",
    "    \"twain_huck\": \"https://www.gutenberg.org/cache/epub/76/pg76.txt\",\n",
    "    \"twain_prince\": \"https://www.gutenberg.org/cache/epub/1837/pg1837.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f1aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book downloaded: ../data/austen_pride.txt\n",
      "Book downloaded: ../data/austen_emma.txt\n",
      "Book downloaded: ../data/austen_sense.txt\n",
      "Book downloaded: ../data/dickens_two_cities.txt\n",
      "Book downloaded: ../data/dickens_expectations.txt\n",
      "Book downloaded: ../data/dickens_twist.txt\n",
      "Book downloaded: ../data/twain_tom.txt\n",
      "Book downloaded: ../data/twain_huck.txt\n",
      "Book downloaded: ../data/twain_prince.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloads a collection of classic literature books from their URLs and \n",
    "saves them as plain text files in a local directory.\n",
    "\n",
    "For each book:\n",
    "1. It sends an HTTP GET request to the Project Gutenberg URL.\n",
    "2. It writes the full text content to a UTF-8 encoded `.txt` file.\n",
    "3. It prints a confirmation message with the file path.\n",
    "\n",
    "The output files are stored in the `../data/` directory and are named \n",
    "based on the keys of the `books_urls` dictionary.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for name, url in books_urls.items():\n",
    "\tresponse = requests.get(url)\n",
    "\tpath = f\"../data/{name}.txt\"\n",
    "\n",
    "\twith open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "\t\tf.write(response.text)\n",
    "\tprint(f\"Book downloaded: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1bbd3",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing and Loading\n",
    "\n",
    "In this section, the raw book texts are cleaned and preprocessed to make them suitable for training machine learning models. This involves removing metadata, tokenizing sentences and words, filtering out stopwords and non-alphabetic tokens, and splitting the texts into manageable chunks. Once processed, the data is loaded and stored so it can be easily accessed and reused throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92543fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nbedo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\nbedo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downloads the required NLTK tokenization models and prepares resources \n",
    "for text preprocessing. Specifically, this section:\n",
    "\n",
    "1. Downloads the 'punkt' and 'punkt_tab' models, which are used by NLTK \n",
    "   for sentence and word tokenization.\n",
    "2. Loads the standard set of English stopwords to filter out common \n",
    "   non-informative words.\n",
    "3. Compiles a regular expression pattern to match valid lowercase words \n",
    "   and simple contractions (e.g., \"don't\", \"it's\") for clean token filtering.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "token_pattern = re.compile(r\"^[a-z]+(?:'[a-z]+)?$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d310a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_gutenberg_headers(text):\n",
    "\n",
    "\t\"\"\"\n",
    "    Removes the standard Project Gutenberg header and footer from a raw text.\n",
    "\n",
    "    Project Gutenberg texts typically contain metadata at the beginning and \n",
    "    end of the file, such as licensing information, title, author notes, and \n",
    "    disclaimers. These sections are marked by standardized delimiters like:\n",
    "    \n",
    "    *** START OF THE PROJECT GUTENBERG EBOOK <title> ***\n",
    "    *** END OF THE PROJECT GUTENBERG EBOOK <title> ***\n",
    "\n",
    "    This function searches for those delimiters using regular expressions \n",
    "    and extracts only the book's main content between them.\n",
    "\n",
    "    Args:\n",
    "        text (str): The full raw text of a Project Gutenberg book.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text containing only the book's main content, \n",
    "             without headers or footers.\n",
    "    \"\"\"\n",
    "\t\n",
    "\tstart_match = re.search(r\"\\*\\*\\*\\s*START OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text, re.IGNORECASE)\n",
    "\tstart_index = start_match.end() if start_match else 0\n",
    "\n",
    "\tend_match = re.search(r\"\\*\\*\\*\\s*END OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text, re.IGNORECASE)\n",
    "\tend_index = end_match.start() if end_match else len(text)\n",
    "\n",
    "\tclean_text = text[start_index:end_index].strip()\n",
    "\treturn clean_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e921d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sent_token_lists(text):\n",
    "\n",
    "\t\"\"\"\n",
    "    Converts a raw text string into a list of tokenized sentences, \n",
    "    applying basic normalization and filtering.\n",
    "\n",
    "    The process involves:\n",
    "    1. Splitting the text into individual sentences.\n",
    "    2. Converting each sentence to lowercase and replacing hyphens with spaces.\n",
    "    3. Tokenizing each sentence into individual word tokens.\n",
    "    4. Filtering out tokens that:\n",
    "       - Do not match the defined `token_pattern` (e.g., non-alphabetic tokens).\n",
    "       - Are purely numeric.\n",
    "       - Are English stopwords.\n",
    "    5. Keeping only sentences that contain at least two valid tokens.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to tokenize and clean.\n",
    "\n",
    "    Returns:\n",
    "        list[list[str]]: A list of sentences, where each sentence is represented \n",
    "                         as a list of cleaned word tokens.\n",
    "    \"\"\"\n",
    "\n",
    "\tsentences = sent_tokenize(text)\n",
    "\ttokenized = []\n",
    "\n",
    "\tfor sentence in sentences:\n",
    "\t\tsentence = sentence.lower()\n",
    "\t\tsentence = sentence.replace(\"-\", \" \")\n",
    "\n",
    "\t\twords = word_tokenize(sentence)\n",
    "\n",
    "\t\tcleaned = [word for word in words if token_pattern.match(word)]\n",
    "\t\tcleaned = [word for word in cleaned if word and not word.isdigit()]\n",
    "\t\tcleaned = [word for word in cleaned if not word in stop_words]\n",
    "\n",
    "\t\tif len(cleaned) >= 2:\n",
    "\t\t\ttokenized.append(cleaned)\n",
    "    \n",
    "\treturn tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a948162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus_from_books(book_dir):\n",
    "    \n",
    "\t\"\"\"\n",
    "    Builds a tokenized sentence corpus from a directory of plain text book files.\n",
    "\n",
    "    This function iterates through all text files in the specified directory, \n",
    "    cleans each book by removing Project Gutenberg headers and footers, \n",
    "    tokenizes the text into sentences and words, and aggregates all processed \n",
    "    sentences into a single corpus list.\n",
    "\n",
    "    Args:\n",
    "        book_dir (str): Path to the directory containing the book `.txt` files.\n",
    "\n",
    "    Returns:\n",
    "        list[list[str]]: A corpus represented as a list of tokenized sentences, \n",
    "                         where each sentence is a list of cleaned word tokens.\n",
    "    \"\"\"\n",
    "     \n",
    "\tall_sentences = []\n",
    "\tfiles = sorted([file for file in os.listdir(book_dir)])\n",
    "\n",
    "\tfor file_name in files:\n",
    "\t\tpath = os.path.join(book_dir, file_name)\n",
    "\t\tprint(f\"Processing {path} ...\")\n",
    "\t\t\n",
    "\t\twith open(path, \"r\", encoding = \"utf-8\") as f:\n",
    "\t\t\traw = f.read()\n",
    "\t\t\t\n",
    "\t\tstripped = strip_gutenberg_headers(raw)\n",
    "\t\tsentences = text_to_sent_token_lists(stripped)\n",
    "\t\tall_sentences.extend(sentences)\n",
    "\t\t\n",
    "\tprint(f\"\\nTotal sentences in corpus: {len(all_sentences)}\")\n",
    "\treturn all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9003e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../data\\austen_emma.txt ...\n",
      "Processing ../data\\austen_pride.txt ...\n",
      "Processing ../data\\austen_sense.txt ...\n",
      "Processing ../data\\dickens_expectations.txt ...\n",
      "Processing ../data\\dickens_twist.txt ...\n",
      "Processing ../data\\dickens_two_cities.txt ...\n",
      "Processing ../data\\twain_huck.txt ...\n",
      "Processing ../data\\twain_prince.txt ...\n",
      "Processing ../data\\twain_tom.txt ...\n",
      "\n",
      "Total sentences in corpus: 42516\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build the full tokenized corpus from the downloaded book collection.\n",
    "\n",
    "This step reads all `.txt` files stored in the `../data` directory, \n",
    "cleans and tokenizes them, and returns a unified list of tokenized sentences. \n",
    "The resulting `all_sentences` corpus will later be used.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "all_sentences = build_corpus_from_books(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efd201",
   "metadata": {},
   "source": [
    "# 3. Training Embedding Models\n",
    "\n",
    "In this section, custom word embeddings are trained using the Word2Vec architecture with negative sampling. The preprocessed sentences are used to learn vector representations of words at different dimensionalities. These trained embeddings capture semantic relationships between words and will later be used to initialize embedding layers in classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16012f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4100b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the configuration parameters for training word embedding models.\n",
    "\n",
    "`dimensions` specifies the different vector sizes to be used when \n",
    "training multiple embedding models (e.g., Word2Vec). Training models \n",
    "with different dimensions allows for later comparison of their \n",
    "performance or quality.\n",
    "\n",
    "`group_code` is a simple identifier that can be used to group, label, \n",
    "or version models trained under the same experiment settings.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dimensions = [50, 100, 200]\n",
    "group_code = \"G01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de70aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_models(sentences, dimensions, group_code, output_dir):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains multiple Word2Vec embedding models with different vector dimensions \n",
    "    and saves both the full model and its word vectors to disk.\n",
    "\n",
    "    For each specified dimension:\n",
    "    1. A Word2Vec model is trained on the provided tokenized sentences.\n",
    "    2. The model is saved in `.model` format for later reloading in Python.\n",
    "    3. The learned word vectors are exported in `.vec` (text) format for \n",
    "       compatibility with external tools (e.g., Gensim's KeyedVectors, \n",
    "       visualization tools, or embedding evaluators).\n",
    "\n",
    "    Args:\n",
    "        sentences (list[list[str]]): The training corpus represented as a list \n",
    "                                     of tokenized sentences.\n",
    "        dimensions (list[int]): A list of vector sizes to train models with.\n",
    "        group_code (str): An identifier used to group or label model files.\n",
    "        output_dir (str): Path to the directory where model files will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    for dimension in dimensions:\n",
    "        print(f\"\\nTraining model with dimension {dimension} ...\")\n",
    "        \n",
    "        model = Word2Vec(\n",
    "            sentences = sentences,\n",
    "            vector_size = dimension,\n",
    "            window = 5,\n",
    "            negative = 20, \n",
    "            min_count = 2,\n",
    "            workers = 8,\n",
    "            sg = 1,\n",
    "            epochs = 40\n",
    "        )\n",
    "        \n",
    "        model_path = os.path.join(output_dir, f\"Books_{dimension}_{group_code}.model\")\n",
    "        vec_path = os.path.join(output_dir, f\"Books_{dimension}_{group_code}.vec\")\n",
    "        \n",
    "        model.save(model_path)\n",
    "        model.wv.save_word2vec_format(vec_path, binary = False)\n",
    "        \n",
    "        print(f\"Model saved in:\\n  - {model_path}\\n  - {vec_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17423dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with dimension 50 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in:\n",
      "  - ../models\\Books_50_G01.model\n",
      "  - ../models\\Books_50_G01.vec\n",
      "\n",
      "Training model with dimension 100 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in:\n",
      "  - ../models\\Books_100_G01.model\n",
      "  - ../models\\Books_100_G01.vec\n",
      "\n",
      "Training model with dimension 200 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in:\n",
      "  - ../models\\Books_200_G01.model\n",
      "  - ../models\\Books_200_G01.vec\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and save Word2Vec models using the preprocessed book corpus.\n",
    "\n",
    "This step trains multiple Word2Vec models with different vector dimensions \n",
    "(defined in `dimensions`) on the `all_sentences` corpus. Each model is \n",
    "saved both in `.model` format (for reloading in Gensim) and `.vec` format \n",
    "(for interoperability with other tools). The `group_code` is used to label \n",
    "the output files consistently.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_and_save_models(all_sentences, dimensions, group_code, \"../models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf84eaf",
   "metadata": {},
   "source": [
    "# 4. Loading the Trained Models\n",
    "\n",
    "In this section, the previously trained Word2Vec embedding models are loaded from disk. These models will be used in the next steps to explore semantic relationships between words and to build embedding matrices for neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a975fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 50D from ../models/Books_50_G01.model ...\n",
      "Word2Vec<vocab=16108, vector_size=50, alpha=0.025>\n",
      "Loading model 100D from ../models/Books_100_G01.model ...\n",
      "Word2Vec<vocab=16108, vector_size=100, alpha=0.025>\n",
      "Loading model 200D from ../models/Books_200_G01.model ...\n",
      "Word2Vec<vocab=16108, vector_size=200, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the previously trained Word2Vec models from disk for later use and evaluation.\n",
    "\n",
    "This step rebuilds the `Word2Vec` objects from the saved `.model` files \n",
    "so they can be queried (e.g., for word similarities, analogies, or \n",
    "embedding visualizations) without retraining.\n",
    "\n",
    "The models are stored in a dictionary keyed by their vector dimensions \n",
    "for easy access.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model_dir = \"../models\"\n",
    "\n",
    "model_paths = {\n",
    "    50: f\"{model_dir}/Books_50_G01.model\",\n",
    "    100: f\"{model_dir}/Books_100_G01.model\",\n",
    "    200: f\"{model_dir}/Books_200_G01.model\"\n",
    "}\n",
    "\n",
    "models = {}\n",
    "for dimension, path in model_paths.items():\n",
    "    print(f\"Loading model {dimension}D from {path} ...\")\n",
    "    models[dimension] = Word2Vec.load(path)\n",
    "    print(models[dimension])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77a1df",
   "metadata": {},
   "source": [
    "# 5. 2D Visualization of Embeddings\n",
    "\n",
    "In this section, the trained word embeddings are projected into a 2D space using the t-SNE technique. This visualization allows us to explore and identify meaningful semantic relationships, focusing on the names of the main characters from each book. By plotting the most similar words to these character names, we can observe how the model groups related terms in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da8c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similar_words(model, target_word, topn = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Visualizes the most similar words to a target word using t-SNE dimensionality reduction.\n",
    "\n",
    "    This function:\n",
    "    1. Retrieves the `topn` most similar words to the `target_word` based on cosine similarity.\n",
    "    2. Extracts their corresponding word vectors from the trained Word2Vec model.\n",
    "    3. Uses t-SNE to project the high-dimensional vectors into a 2D space.\n",
    "    4. Plots the target word and its similar words in a scatter plot for intuitive inspection.\n",
    "\n",
    "    Args:\n",
    "        model (gensim.models.Word2Vec): The trained Word2Vec model to query.\n",
    "        target_word (str): The word whose similar neighbors will be visualized.\n",
    "        topn (int, optional): Number of similar words to retrieve and plot. Default is 5.\n",
    "    \"\"\"\n",
    "\n",
    "    similar_words = [w for w, _ in model.wv.most_similar(target_word, topn = topn)]\n",
    "    all_words = [target_word] + similar_words\n",
    "\n",
    "    vectors = np.array([model.wv[w] for w in all_words])\n",
    "\n",
    "    tsne = TSNE(n_components = 2, random_state = 42, perplexity = 5)\n",
    "    reduced = tsne.fit_transform(vectors)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(reduced[:, 0], reduced[:, 1])\n",
    "\n",
    "    for i, word in enumerate(all_words):\n",
    "        if i == 0:\n",
    "            plt.annotate(word, xy = (reduced[i, 0], reduced[i, 1]), fontsize = 14, color = 'red', fontweight = 'bold')\n",
    "        else:\n",
    "            plt.annotate(word, xy = (reduced[i, 0], reduced[i, 1]), fontsize = 12)\n",
    "\n",
    "    plt.title(f\"Words most similar to '{target_word}'\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dictionary mapping each book (by its identifier) to a list of its main characters.\n",
    "\n",
    "This structure is useful for querying trained Word2Vec models about \n",
    "relationships between characters, visualizing their embeddings, or \n",
    "analyzing co-occurrences within the corpus.\n",
    "\n",
    "The keys correspond to the identifiers used in `books_urls`, while the \n",
    "values are lists containing the names of the primary characters from \n",
    "each book in lowercase (to match tokenized forms).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "main_characters = {\n",
    "    \"austen_pride\": [\"elizabeth\", \"darcy\"],       \n",
    "    \"austen_emma\": [\"emma\", \"knightley\"],         \n",
    "    \"austen_sense\": [\"elinor\", \"marianne\"],       \n",
    "\n",
    "    \"dickens_two_cities\": [\"darnay\", \"carton\"],   \n",
    "    \"dickens_expectations\": [\"pip\", \"havisham\"],  \n",
    "    \"dickens_twist\": [\"oliver\", \"fagin\"],         \n",
    "\n",
    "    \"twain_tom\": [\"tom\", \"becky\"],               \n",
    "    \"twain_huck\": [\"huck\", \"jim\"],               \n",
    "    \"twain_prince\": [\"prince\", \"pauper\"],        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d930095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_similar_words(model, target_word, book_id, dimension, topn, output_dir):\n",
    "    \n",
    "\t\"\"\"\n",
    "    Generates and saves a 2D visualization of the most similar words to a given target word\n",
    "    using t-SNE for dimensionality reduction.\n",
    "\n",
    "    This function:\n",
    "    1. Retrieves the `topn` most similar words to the `target_word` from the model.\n",
    "    2. Reduces the vectors of the target word and its similar words to 2D using t-SNE.\n",
    "    3. Creates a scatter plot with the target word highlighted in red and the similar words\n",
    "       annotated around it.\n",
    "    4. Saves the resulting figure as a PNG file to the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        model (gensim.models.Word2Vec): The trained Word2Vec model.\n",
    "        target_word (str): The word to visualize and find similar neighbors for.\n",
    "        book_id (str): Identifier of the book, used for labeling the plot.\n",
    "        dimension (int): Dimensionality of the Word2Vec model used.\n",
    "        topn (int): Number of most similar words to retrieve.\n",
    "        output_dir (str): Directory where the generated plot image will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "\tsimilar_words = model.wv.most_similar(target_word, topn = topn)\n",
    "\twords = [target_word] + [w for w, _ in similar_words]\n",
    "\tvectors = np.array([model.wv[w] for w in words])\n",
    "\n",
    "\ttsne = TSNE(n_components = 2, random_state = 42, perplexity = min(5, len(words)-1))\n",
    "\treduced = tsne.fit_transform(vectors)\n",
    "\n",
    "\tplt.figure(figsize=(8, 6))\n",
    "\tplt.scatter(reduced[0, 0], reduced[0, 1], color = 'red')  \n",
    "\tplt.text(reduced[0, 0] + 1, reduced[0, 1] + 1, target_word, fontsize = 12, color = 'red', weight = 'bold')\n",
    "\n",
    "\tfor i, word in enumerate(words[1:], start = 1):\n",
    "\t\tx, y = reduced[i, 0], reduced[i, 1]\n",
    "\t\tplt.scatter(x, y)\n",
    "\t\tplt.text(x + 1, y + 1, word, fontsize=10)\n",
    "\n",
    "\tplt.title(f\"Most similar to '{target_word}' ({book_id}, dim = {dimension})\")\n",
    "\tplt.tight_layout()\n",
    "\n",
    "\tfilename = f\"{target_word}_{dimension}d.png\"\n",
    "\tfilepath = os.path.join(output_dir, filename)\n",
    "\tplt.savefig(filepath)\n",
    "\tplt.close()  \n",
    "\tprint(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce8f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../figures\\elizabeth_50d.png\n",
      "Saved: ../figures\\darcy_50d.png\n",
      "Saved: ../figures\\emma_50d.png\n",
      "Saved: ../figures\\knightley_50d.png\n",
      "Saved: ../figures\\elinor_50d.png\n",
      "Saved: ../figures\\marianne_50d.png\n",
      "Saved: ../figures\\darnay_50d.png\n",
      "Saved: ../figures\\carton_50d.png\n",
      "Saved: ../figures\\pip_50d.png\n",
      "Saved: ../figures\\havisham_50d.png\n",
      "Saved: ../figures\\oliver_50d.png\n",
      "Saved: ../figures\\fagin_50d.png\n",
      "Saved: ../figures\\tom_50d.png\n",
      "Saved: ../figures\\becky_50d.png\n",
      "Saved: ../figures\\huck_50d.png\n",
      "Saved: ../figures\\jim_50d.png\n",
      "Saved: ../figures\\prince_50d.png\n",
      "Saved: ../figures\\pauper_50d.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate and save similarity visualizations for each main character across all books \n",
    "using the 50-dimensional Word2Vec model.\n",
    "\n",
    "For each book in `main_characters`, this loop:\n",
    "1. Iterates through its main character names.\n",
    "2. Calls `plot_and_save_similar_words` to generate a 2D t-SNE plot showing the character \n",
    "   and its top 4 most similar words in the embedding space.\n",
    "3. Saves each figure as a PNG file in the `../figures` directory.\n",
    "\n",
    "This provides an easy way to inspect how well the embedding model has captured \n",
    "the semantic context of key literary characters.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for book_id, characters in main_characters.items():\n",
    "\tfor name in characters:\n",
    "\t\tplot_and_save_similar_words(models[50], name, book_id, 50, 4, \"../figures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556b908",
   "metadata": {},
   "source": [
    "# 6. Dataset Preparation for Classification\n",
    "\n",
    "In this section, the data is prepared for training classification models. The raw text is preprocessed, tokenized, and divided into fixed-size chunks to create consistent input samples. The dataset is then split into training, validation, and test sets, ensuring class balance across splits. This structured format allows the data to be used effectively by neural network architectures in the following stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eed56787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mappings between book filenames, their corresponding authors, and numeric labels.\n",
    "\n",
    "`books_to_author` maps each text file containing a book to the author's name as a string.\n",
    "This is useful for tasks such as author attribution, where we need to associate each\n",
    "book with its original author.\n",
    "\n",
    "`labels_to_ids` provides a mapping from author names to numeric identifiers.\n",
    "These numeric labels are typically required for machine learning models that expect\n",
    "categorical values to be encoded as integers.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "books_to_author = {\n",
    "    \"austen_pride.txt\": \"austen\",\n",
    "    \"austen_emma.txt\": \"austen\",\n",
    "    \"austen_sense.txt\": \"austen\",\n",
    "    \"dickens_two_cities.txt\": \"dickens\",\n",
    "    \"dickens_expectations.txt\": \"dickens\",\n",
    "    \"dickens_twist.txt\": \"dickens\",\n",
    "    \"twain_tom.txt\": \"twain\",\n",
    "    \"twain_huck.txt\": \"twain\",\n",
    "    \"twain_prince.txt\": \"twain\",\n",
    "}\n",
    "\n",
    "labels_to_ids = {\n",
    "    \"austen\": 0,\n",
    "    \"dickens\": 1,\n",
    "    \"twain\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f269ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    \n",
    "\t\"\"\"\n",
    "    Read the contents of a text file and return it as a string.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the text file to be read.\n",
    "\n",
    "    Returns:\n",
    "        str: The full contents of the file as a single string.\n",
    "    \"\"\"\n",
    "\t\t\n",
    "\twith open(path, \"r\", encoding = \"utf-8\") as f:\n",
    "\t\treturn f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c506cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_chunks(text, chunk_size, min_chunk_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocess text into clean word tokens and split them into fixed-size chunks.\n",
    "\n",
    "    This function performs sentence tokenization, lowercasing, hyphen replacement,\n",
    "    word tokenization, filtering by regex pattern, removal of digits and stopwords,\n",
    "    and finally splits the resulting token sequence into chunks of a specified size.\n",
    "    Chunks shorter than `min_chunk_size` are discarded.\n",
    "\n",
    "    Args:\n",
    "        text (str): Raw text to preprocess.\n",
    "        chunk_size (int): Number of tokens per chunk.\n",
    "        min_chunk_size (int): Minimum number of tokens required for a chunk to be kept.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of preprocessed text chunks, each represented as a space-separated string.\n",
    "    \"\"\"\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    all_tokens = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "\n",
    "        words = word_tokenize(sentence)\n",
    "\n",
    "        cleaned = [word for word in words if token_pattern.match(word)]\n",
    "        cleaned = [word for word in cleaned if not word.isdigit()]\n",
    "        cleaned = [word for word in cleaned if word not in stop_words]\n",
    "\n",
    "        if len(cleaned) >= 1:\n",
    "            all_tokens.extend(cleaned)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(all_tokens), chunk_size):\n",
    "        chunk_tokens = all_tokens[i:i+chunk_size]\n",
    "        if len(chunk_tokens) >= min_chunk_size:\n",
    "            chunk_text = \" \".join(chunk_tokens)\n",
    "            chunks.append(chunk_text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cba0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clasification_dataset(books_dir, test_size, validation_size, random_seed):\n",
    "\n",
    "\t\"\"\"\n",
    "    Build a text classification dataset from preprocessed book chunks, splitting into train, validation, and test sets.\n",
    "\n",
    "    This function reads all book files from a directory, preprocesses their content into token chunks,\n",
    "    assigns each chunk a numeric label based on the book's author, and splits the resulting dataset\n",
    "    into training, validation, and test subsets using stratified sampling to preserve class balance.\n",
    "\n",
    "    Args:\n",
    "        books_dir (str): Path to the directory containing the book text files.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        validation_size (float): Proportion of the remaining data (after train split) to allocate to validation.\n",
    "        random_seed (int): Seed used for reproducible shuffling and splitting.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three datasets:\n",
    "            - (X_train, y_train): Training texts and labels.\n",
    "            - (X_validation, y_validation): Validation texts and labels.\n",
    "            - (X_test, y_test): Test texts and labels.\n",
    "    \"\"\"\n",
    "\t \n",
    "\trandom.seed(random_seed)\n",
    "\ttexts, labels = [], []\n",
    "\n",
    "\tfor file_name in sorted(os.listdir(books_dir)):\n",
    "\t\tauthor = books_to_author.get(file_name)\n",
    "\t\t\n",
    "\t\traw_text = read_text(os.path.join(books_dir, file_name))\n",
    "\t\tchunks = preprocess_and_chunks(raw_text, 200, 200)\n",
    "\t\tprint(f\"{len(chunks)} chunks generated for {file_name}\")\n",
    "\n",
    "\t\ttexts.extend(chunks)\n",
    "\t\tlabels.extend([author] * len(chunks))\n",
    "\n",
    "\ty = np.array([labels_to_ids[label] for label in labels])\n",
    "\n",
    "\tX_train, X_temp, y_train, y_temp = train_test_split(texts, y, test_size = test_size, random_state = random_seed, stratify = y)\n",
    "\tX_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size = validation_size, random_state = random_seed, stratify = y_temp)\n",
    "\n",
    "\tdef class_counts(y_arr):\n",
    "\t\tc = Counter(y_arr)\n",
    "\t\treturn {label: c[idx] for label, idx in labels_to_ids.items()}\n",
    "\n",
    "\tsummary = {\n",
    "\t\t\"train\": class_counts(y_train),\n",
    "\t\t\"validation\": class_counts(y_validation),\n",
    "\t\t\"test\": class_counts(y_test),\n",
    "\t}\n",
    "\n",
    "\tprint(\"\\nSummary samples by split and class:\\n\")\n",
    "\tfor split, counts in summary.items():\n",
    "\t\tprint(f\"  {split}: {counts}\")\n",
    "\n",
    "\treturn (X_train, y_train), (X_validation, y_validation), (X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 chunks generated for austen_emma.txt\n",
      "287 chunks generated for austen_pride.txt\n",
      "268 chunks generated for austen_sense.txt\n",
      "411 chunks generated for dickens_expectations.txt\n",
      "384 chunks generated for dickens_twist.txt\n",
      "322 chunks generated for dickens_two_cities.txt\n",
      "252 chunks generated for twain_huck.txt\n",
      "185 chunks generated for twain_prince.txt\n",
      "175 chunks generated for twain_tom.txt\n",
      "\n",
      "Summary samples by split and class:\n",
      "\n",
      "  train: {'austen': 632, 'dickens': 782, 'twain': 428}\n",
      "  validation: {'austen': 135, 'dickens': 168, 'twain': 92}\n",
      "  test: {'austen': 136, 'dickens': 167, 'twain': 92}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build the classification dataset and split it into train, validation, and test sets.\n",
    "\n",
    "This line applies the `build_clasification_dataset` function to the book corpus stored in `../data`.\n",
    "The dataset is split with 30% of the data reserved for testing, and 50% of the remaining data\n",
    "allocated to validation. A fixed random seed (42) is used to ensure reproducibility.\n",
    "\n",
    "Returns:\n",
    "    (X_train, y_train): Training texts and labels.\n",
    "    (X_validation, y_validation): Validation texts and labels.\n",
    "    (X_test, y_test): Test texts and labels.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_validation, y_validation), (X_test, y_test) = build_clasification_dataset(\"../data\", 0.3, 0.5, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6cfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Train examples ---\n",
      "Label: austen\n",
      "Text: rather dark darker narrower one could wish miss sm ...\n",
      "\n",
      "Label: dickens\n",
      "Text: stood drinking little counter conversation defarge ...\n",
      "\n",
      "\n",
      "--- Validation examples ---\n",
      "Label: twain\n",
      "Text: office child play wherefore last ladies visit draw ...\n",
      "\n",
      "Label: dickens\n",
      "Text: condition declared peril sake altering way living  ...\n",
      "\n",
      "\n",
      "--- Test examples ---\n",
      "Label: austen\n",
      "Text: well satisfied consider present campbells may knig ...\n",
      "\n",
      "Label: dickens\n",
      "Text: though would shake hands let go room said boy retr ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspect a few example samples from each dataset split (Train, Validation, Test).\n",
    "\n",
    "This loop iterates through the three splits and prints two representative examples \n",
    "from each. For each example, it displays the human-readable class label (mapped from \n",
    "its numeric ID) and the first 50 characters of the corresponding text chunk.\n",
    "\n",
    "This is a useful sanity check to ensure that:\n",
    "    - The dataset has been split correctly.\n",
    "    - The labels correspond to the right author.\n",
    "    - The text chunks are correctly preprocessed and non-empty.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for split_name, X_split, y_split in [(\"Train\", X_train, y_train), (\"Validation\", X_validation, y_validation), (\"Test\", X_test, y_test),]:\n",
    "    print(f\"\\n--- {split_name} examples ---\")\n",
    "    for i in range(2): \n",
    "        print(f\"Label: {list(labels_to_ids.keys())[list(labels_to_ids.values()).index(y_split[i])]}\")\n",
    "        print(\"Text:\", \"\".join(X_split[i][:50]), \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb892f40",
   "metadata": {},
   "source": [
    "# 7. Building Embeddings Matrix\n",
    "\n",
    "In this section, embedding matrices are constructed from the previously trained Word2Vec models. Each matrix maps the tokenizer's vocabulary to its corresponding vector representation in the embedding space. These matrices will later be used to initialize the embedding layers of different neural network architectures, enabling the models to leverage pretrained semantic knowledge during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e568120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216809ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vocabulary size: 21023\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenize the training texts and build the vocabulary for the classification model.\n",
    "\n",
    "1. `sequence_length` is set to 200, matching the chunk size used during preprocessing.\n",
    "2. A Keras `Tokenizer` is initialized with an out-of-vocabulary token `<OOV>` to handle \n",
    "   unseen words during inference.\n",
    "3. The tokenizer is fitted on the training set to build the vocabulary.\n",
    "\n",
    "This tokenizer will later be used to convert text chunks into integer sequences for \n",
    "training a neural network classifier.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sequence_length = 200\n",
    "\n",
    "tokenizer = Tokenizer(oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_index) + 1\n",
    "print(\"Training vocabulary size:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(embeddings_model, tokenizer, embedding_dimension):\n",
    "    \n",
    "\t\"\"\"\n",
    "    Build an embedding matrix aligned with the tokenizer's vocabulary using a pre-trained Word2Vec model.\n",
    "\n",
    "    For each word in the tokenizer's vocabulary, this function looks up the corresponding\n",
    "    vector in the Word2Vec model. If the word is found, its vector is placed at the\n",
    "    appropriate index in the embedding matrix. Words not present in the Word2Vec model\n",
    "    remain as zero vectors.\n",
    "\n",
    "    Args:\n",
    "        embeddings_model (gensim.models.Word2Vec): Pre-trained Word2Vec model containing word embeddings.\n",
    "        tokenizer (keras.preprocessing.text.Tokenizer): Tokenizer fitted on the training texts.\n",
    "        embedding_dimension (int): Dimensionality of the word vectors in the Word2Vec model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array of shape (vocabulary_size, embedding_dimension) where each row\n",
    "                    corresponds to a token index and contains its embedding vector.\n",
    "    \"\"\"\n",
    "     \n",
    "\tmatrix = np.zeros((vocabulary_size, embedding_dimension))\n",
    "\tfor word, i in tokenizer.word_index.items():\n",
    "\t\tif word in embeddings_model.wv:\n",
    "\t\t\tmatrix[i] = embeddings_model.wv[word]\n",
    "\treturn matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4dd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create embedding matrices for each pre-trained Word2Vec model dimension.\n",
    "\n",
    "For each embedding model (50D, 100D, 200D), this loop builds an embedding matrix \n",
    "aligned with the tokenizer's vocabulary using `build_embedding_matrix`. \n",
    "The resulting matrices are stored in the `embedding_matrices` dictionary, \n",
    "keyed by their embedding dimension.\n",
    "\n",
    "These matrices will later be used to initialize the embedding layers \n",
    "of different neural network models for text classification.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "embedding_matrices = {}\n",
    "for dimension, embedding_model in models.items():\n",
    "    embedding_matrices[dimension] = build_embedding_matrix(embedding_model, tokenizer, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6307338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert text datasets into integer sequences using the fitted tokenizer.\n",
    "\n",
    "Each text chunk in the training, validation, and test sets is transformed \n",
    "into a sequence of integer token IDs based on the tokenizer's vocabulary. \n",
    "These sequences will later be padded to a fixed length and fed into \n",
    "the neural network models.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X_train_sequences = np.array(tokenizer.texts_to_sequences(X_train))\n",
    "X_validation_sequences = np.array(tokenizer.texts_to_sequences(X_validation))\n",
    "X_test_sequences  = np.array(tokenizer.texts_to_sequences(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd79f6",
   "metadata": {},
   "source": [
    "# 8. Training Feed-Forward Model for Classification (Trained Embeddings)\n",
    "\n",
    "In this section, several feed-forward neural network architectures are trained for author classification using the custom Word2Vec embeddings. Each model leverages the pretrained embedding matrices as non-trainable layers, allowing the network to focus on learning classification patterns rather than word representations. The models are evaluated on validation and test sets to measure their accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55bc2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Flatten, Dense\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "643b269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_authors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_layer(embedding_matrix):\n",
    "\n",
    "\t\"\"\"\n",
    "    Create a non-trainable Keras Embedding layer initialized with a pre-trained embedding matrix.\n",
    "\n",
    "    This function constructs an `Embedding` layer using the provided matrix, \n",
    "    where each row corresponds to a token index and contains its pre-trained \n",
    "    embedding vector. The layer is set to `trainable=False` to keep the \n",
    "    embeddings fixed during model training, ensuring that the model relies \n",
    "    on the semantic structure learned by the Word2Vec model.\n",
    "\n",
    "    Args:\n",
    "        embedding_matrix (np.ndarray): A 2D NumPy array of shape \n",
    "            (vocabulary_size, embedding_dimension) containing pre-trained embeddings.\n",
    "\n",
    "    Returns:\n",
    "        keras.layers.Embedding: A configured embedding layer ready to be used \n",
    "        as the first layer in a neural network model.\n",
    "    \"\"\"\t\n",
    "\t\n",
    "\tembedding_dimension = embedding_matrix.shape[1]\n",
    "\n",
    "\treturn Embedding(\n",
    "\t\tinput_dim = vocabulary_size,\n",
    "\t\toutput_dim = embedding_dimension,\n",
    "\t\tweights = [embedding_matrix],\n",
    "\t\ttrainable = False\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040ce2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_a(embedding_layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Build a simple neural network for text classification using average pooling.\n",
    "\n",
    "    This model architecture consists of:\n",
    "        1. A pre-trained, non-trainable embedding layer.\n",
    "        2. A `GlobalAveragePooling1D` layer that computes the average vector \n",
    "           representation of the input sequence.\n",
    "        3. A dense hidden layer with ReLU activation for non-linear feature extraction.\n",
    "        4. A softmax output layer with `num_authors` units for multi-class classification.\n",
    "\n",
    "    Args:\n",
    "        embedding_layer (keras.layers.Embedding): Pre-initialized embedding layer \n",
    "            built with `make_embedding_layer`.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(32, activation = 'relu'),\n",
    "        Dense(num_authors, activation = 'softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_b(embedding_layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Build a deeper feed-forward neural network for text classification.\n",
    "\n",
    "    This model extends `build_model_a` by adding an extra dense layer with \n",
    "    more units, allowing it to learn more complex feature interactions from \n",
    "    the averaged embeddings. The architecture consists of:\n",
    "\n",
    "        1. A pre-trained, non-trainable embedding layer.\n",
    "        2. A `GlobalAveragePooling1D` layer to aggregate token embeddings.\n",
    "        3. A dense hidden layer with 128 units and ReLU activation.\n",
    "        4. A second dense hidden layer with 64 units and ReLU activation.\n",
    "        5. A softmax output layer with `num_authors` units for classification.\n",
    "\n",
    "    Args:\n",
    "        embedding_layer (keras.layers.Embedding): Pre-initialized embedding layer \n",
    "            built with `make_embedding_layer`.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(128, activation = 'relu'),\n",
    "        Dense(64, activation = 'relu'),\n",
    "        Dense(num_authors, activation = 'softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c40d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_c(embedding_layer):\n",
    "    \n",
    "\t\"\"\"\n",
    "    Build a neural network for text classification using flattened embeddings.\n",
    "\n",
    "    Unlike the previous models that use average pooling, this architecture \n",
    "    flattens the entire sequence of embeddings into a single long vector \n",
    "    before passing it through dense layers. This allows the model to preserve \n",
    "    the positional structure of the sequence, at the cost of more parameters.\n",
    "\n",
    "    The architecture consists of:\n",
    "        1. A pre-trained, non-trainable embedding layer.\n",
    "        2. A `Flatten` layer to convert the (sequence_length × embedding_dim) \n",
    "           tensor into a 1D vector.\n",
    "        3. A dense hidden layer with 256 units and ReLU activation.\n",
    "        4. A second dense hidden layer with 128 units and ReLU activation.\n",
    "        5. A softmax output layer with `num_authors` units for classification.\n",
    "\n",
    "    Args:\n",
    "        embedding_layer (keras.layers.Embedding): Pre-initialized embedding layer \n",
    "            built with `make_embedding_layer`.\n",
    "\n",
    "    Returns:\n",
    "        keras.models.Sequential: A Keras Sequential model.\n",
    "    \"\"\"\n",
    "      \n",
    "\tmodel = Sequential([\n",
    "\t\tembedding_layer,\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256, activation = 'relu'),\n",
    "\t\tDense(128, activation = 'relu'),\n",
    "\t\tDense(num_authors, activation = 'softmax')\n",
    "\t])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaafef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dictionary of model architecture builders.\n",
    "\n",
    "This dictionary maps architecture names (\"A\", \"B\", \"C\") to their corresponding \n",
    "model-building functions (`build_model_a`, `build_model_b`, `build_model_c`). \n",
    "It provides a clean way to dynamically select and build different neural \n",
    "network architectures for experimentation and comparison.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "architectures = {\n",
    "    \"A\": build_model_a,\n",
    "    \"B\": build_model_b,\n",
    "    \"C\": build_model_c\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model A with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6308 - loss: 0.9395 - val_accuracy: 0.7241 - val_loss: 0.8330\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7953 - loss: 0.7301 - val_accuracy: 0.8228 - val_loss: 0.6366\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8599 - loss: 0.5447 - val_accuracy: 0.8835 - val_loss: 0.4722\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9110 - loss: 0.4099 - val_accuracy: 0.9266 - val_loss: 0.3630\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.3193 - val_accuracy: 0.9494 - val_loss: 0.2874\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9511 - loss: 0.2567 - val_accuracy: 0.9443 - val_loss: 0.2341\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9577 - loss: 0.2139 - val_accuracy: 0.9544 - val_loss: 0.1966\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9615 - loss: 0.1829 - val_accuracy: 0.9646 - val_loss: 0.1756\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9647 - loss: 0.1621 - val_accuracy: 0.9646 - val_loss: 0.1513\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.1468 - val_accuracy: 0.9671 - val_loss: 0.1356\n",
      "Training model B with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7557 - loss: 0.7424 - val_accuracy: 0.9316 - val_loss: 0.4108\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.2657 - val_accuracy: 0.9620 - val_loss: 0.1691\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9549 - loss: 0.1473 - val_accuracy: 0.9671 - val_loss: 0.1126\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9696 - loss: 0.1069 - val_accuracy: 0.9671 - val_loss: 0.0861\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.0942 - val_accuracy: 0.9747 - val_loss: 0.0746\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0798 - val_accuracy: 0.9747 - val_loss: 0.0656\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9734 - loss: 0.0743 - val_accuracy: 0.9747 - val_loss: 0.0682\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0680 - val_accuracy: 0.9747 - val_loss: 0.0586\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0718 - val_accuracy: 0.9722 - val_loss: 0.0713\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0650 - val_accuracy: 0.9797 - val_loss: 0.0507\n",
      "Training model C with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8529 - loss: 0.3710 - val_accuracy: 0.9468 - val_loss: 0.1241\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0170 - val_accuracy: 0.9570 - val_loss: 0.1100\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9595 - val_loss: 0.1048\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 8.0426e-04 - val_accuracy: 0.9646 - val_loss: 0.0980\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 5.1198e-04 - val_accuracy: 0.9646 - val_loss: 0.1006\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.4972e-04 - val_accuracy: 0.9620 - val_loss: 0.1029\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.5457e-04 - val_accuracy: 0.9646 - val_loss: 0.1046\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.9427e-04 - val_accuracy: 0.9646 - val_loss: 0.1057\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.5115e-04 - val_accuracy: 0.9620 - val_loss: 0.1067\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.2075e-04 - val_accuracy: 0.9620 - val_loss: 0.1076\n",
      "Training model A with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6634 - loss: 0.9447 - val_accuracy: 0.7671 - val_loss: 0.8047\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8355 - loss: 0.6899 - val_accuracy: 0.8987 - val_loss: 0.5698\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.4922 - val_accuracy: 0.8886 - val_loss: 0.4206\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9235 - loss: 0.3668 - val_accuracy: 0.9443 - val_loss: 0.3172\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.2895 - val_accuracy: 0.9494 - val_loss: 0.2552\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.2359 - val_accuracy: 0.9544 - val_loss: 0.2195\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9593 - loss: 0.2001 - val_accuracy: 0.9570 - val_loss: 0.1817\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9663 - loss: 0.1730 - val_accuracy: 0.9646 - val_loss: 0.1588\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.1539 - val_accuracy: 0.9646 - val_loss: 0.1413\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.1376 - val_accuracy: 0.9696 - val_loss: 0.1280\n",
      "Training model B with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7324 - loss: 0.7685 - val_accuracy: 0.8481 - val_loss: 0.4377\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9191 - loss: 0.2927 - val_accuracy: 0.9494 - val_loss: 0.1838\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1444 - val_accuracy: 0.9620 - val_loss: 0.1165\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.1000 - val_accuracy: 0.9646 - val_loss: 0.0866\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0752 - val_accuracy: 0.9696 - val_loss: 0.0769\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0718 - val_accuracy: 0.9696 - val_loss: 0.0640\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0677 - val_accuracy: 0.9722 - val_loss: 0.0543\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0630 - val_accuracy: 0.9772 - val_loss: 0.0492\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0580 - val_accuracy: 0.9823 - val_loss: 0.0450\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0516 - val_accuracy: 0.9848 - val_loss: 0.0408\n",
      "Training model C with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8301 - loss: 0.4349 - val_accuracy: 0.9468 - val_loss: 0.1442\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0145 - val_accuracy: 0.9570 - val_loss: 0.1158\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9570 - val_loss: 0.1139\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.9070e-04 - val_accuracy: 0.9595 - val_loss: 0.1158\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.3625e-04 - val_accuracy: 0.9595 - val_loss: 0.1159\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.5056e-04 - val_accuracy: 0.9620 - val_loss: 0.1187\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4718e-04 - val_accuracy: 0.9620 - val_loss: 0.1185\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8498e-04 - val_accuracy: 0.9620 - val_loss: 0.1195\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.3937e-04 - val_accuracy: 0.9620 - val_loss: 0.1206\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0449e-04 - val_accuracy: 0.9595 - val_loss: 0.1225\n",
      "Training model A with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6954 - loss: 0.9012 - val_accuracy: 0.8304 - val_loss: 0.7110\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8648 - loss: 0.5791 - val_accuracy: 0.9063 - val_loss: 0.4563\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9137 - loss: 0.3870 - val_accuracy: 0.9316 - val_loss: 0.3221\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9376 - loss: 0.2808 - val_accuracy: 0.9519 - val_loss: 0.2456\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9577 - loss: 0.2189 - val_accuracy: 0.9595 - val_loss: 0.1974\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.1775 - val_accuracy: 0.9595 - val_loss: 0.1631\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.1503 - val_accuracy: 0.9671 - val_loss: 0.1421\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.1295 - val_accuracy: 0.9671 - val_loss: 0.1278\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.1160 - val_accuracy: 0.9696 - val_loss: 0.1116\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.1036 - val_accuracy: 0.9722 - val_loss: 0.0996\n",
      "Training model B with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7557 - loss: 0.6950 - val_accuracy: 0.9342 - val_loss: 0.3124\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1953 - val_accuracy: 0.9646 - val_loss: 0.1279\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1018 - val_accuracy: 0.9722 - val_loss: 0.1102\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0795 - val_accuracy: 0.9747 - val_loss: 0.0754\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9761 - loss: 0.0647 - val_accuracy: 0.9747 - val_loss: 0.0590\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0625 - val_accuracy: 0.9772 - val_loss: 0.0532\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0575 - val_accuracy: 0.9823 - val_loss: 0.0595\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.0509 - val_accuracy: 0.9772 - val_loss: 0.0603\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0501 - val_accuracy: 0.9823 - val_loss: 0.0532\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.0467 - val_accuracy: 0.9823 - val_loss: 0.0519\n",
      "Training model C with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7818 - loss: 0.6414 - val_accuracy: 0.9468 - val_loss: 0.1661\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9957 - loss: 0.0223 - val_accuracy: 0.9494 - val_loss: 0.1197\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9443 - val_loss: 0.1207\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 7.5317e-04 - val_accuracy: 0.9494 - val_loss: 0.1222\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.2503e-04 - val_accuracy: 0.9494 - val_loss: 0.1250\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6252e-04 - val_accuracy: 0.9570 - val_loss: 0.1213\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.5922e-05 - val_accuracy: 0.9494 - val_loss: 0.1256\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.3062e-05 - val_accuracy: 0.9519 - val_loss: 0.1262\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.4774e-05 - val_accuracy: 0.9519 - val_loss: 0.1278\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 3.3874e-05 - val_accuracy: 0.9544 - val_loss: 0.1288\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code block trains and evaluates multiple text classification models using different \n",
    "embedding dimensions and neural network architectures. For each combination of embedding \n",
    "matrix and architecture, it builds a Keras model, trains it on the training data, validates \n",
    "it on a separate validation set, and evaluates it on the test set.\n",
    "\n",
    "The workflow proceeds as follows:\n",
    "1. Iterate over all available embedding matrices, each corresponding to a specific \n",
    "   embedding dimensionality (e.g., 50D, 100D, 200D).\n",
    "2. For each embedding dimension, iterate over all predefined model architectures (A, B, C), \n",
    "   where each architecture defines a different neural network structure.\n",
    "3. Build an embedding layer from the current embedding matrix and pass it to the model \n",
    "   construction function.\n",
    "4. Compile the model using the Adam optimizer and sparse categorical cross-entropy loss.\n",
    "5. Train the model for 10 epochs on the training data, using the validation set for \n",
    "   monitoring performance.\n",
    "6. Generate predictions on the test set and compute evaluation metrics: accuracy, \n",
    "   precision (macro-averaged), and recall (macro-averaged).\n",
    "7. Store the performance metrics for each (architecture, embedding dimension) pair \n",
    "   in the `results` dictionary for later comparison.\n",
    "\n",
    "The `results` dictionary uses keys in the format \"{ARCH}_{DIM}D\" (e.g., \"A_50D\") and maps \n",
    "them to metric dictionaries with the following structure:\n",
    "{\n",
    "    \"accuracy\": float,\n",
    "    \"precision\": float,\n",
    "    \"recall\": float\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for embedding_dimension, embedding_matrix in embedding_matrices.items():\n",
    "    for arch_name, build_fn in architectures.items():\n",
    "        print(f\"Training model {arch_name} with embedding {embedding_dimension}D\")\n",
    "\n",
    "        embedding_layer = make_embedding_layer(embedding_matrix)\n",
    "        model = build_fn(embedding_layer)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = Adam(),\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train_sequences, y_train,\n",
    "            validation_data = (X_validation_sequences, y_validation),\n",
    "            epochs = 10,\n",
    "            batch_size = 32,\n",
    "            verbose = 1\n",
    "        )\n",
    "\n",
    "        y_pred_probs = model.predict(X_test_sequences, verbose = 0)\n",
    "        y_pred = np.argmax(y_pred_probs, axis = 1)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
    "        recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
    "\n",
    "        key = f\"{arch_name}_{embedding_dimension}D\"\n",
    "        results[key] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47f7890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       accuracy precision recall\n",
      "A_50D     0.967     0.966  0.968\n",
      "B_50D     0.972     0.967  0.976\n",
      "C_50D     0.965     0.964  0.963\n",
      "A_100D    0.957     0.959  0.954\n",
      "B_100D    0.980     0.976  0.983\n",
      "C_100D    0.954     0.959  0.948\n",
      "A_200D    0.970     0.966  0.972\n",
      "B_200D    0.980     0.979  0.980\n",
      "C_200D    0.952     0.958  0.941\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code block converts the collected training and evaluation results into a \n",
    "readable tabular format using a pandas DataFrame.\n",
    "\n",
    "The resulting table allows quick inspection of which architecture–embedding combination \n",
    "performed best across the various metrics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results).T \n",
    "\n",
    "df_formatted = df.map(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "print(df_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4574e0",
   "metadata": {},
   "source": [
    "# 9. Training Feed-Forward Model for Classification (Glove Embeddings)\n",
    "\n",
    "In this section, the same feed-forward neural network architectures are trained for author classification, but this time using pretrained GloVe embeddings. By leveraging these widely used embeddings, the models can benefit from rich semantic representations learned from large external corpora. The goal is to compare their performance against the custom-trained embeddings and evaluate how well external embeddings generalize to the literary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "986d88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ad1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code block defines file paths to pre-trained GloVe embedding files with different \n",
    "vector dimensions (50, 100, and 200).\n",
    "\n",
    "Steps:\n",
    "1. `glove_dir` specifies the base directory where the GloVe files are stored.\n",
    "2. `model_paths` is a dictionary that maps each embedding dimension (key) to its \n",
    "   corresponding file path (value). For example, the 50-dimensional embeddings are \n",
    "   located at `../models/glove.6b/glove.6b.50d.txt`.\n",
    "\n",
    "These paths will be used later to load the corresponding GloVe embeddings and integrate \n",
    "them into the classification models.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "glove_dir = \"../models/glove.6b\"\n",
    "\n",
    "model_paths = {\n",
    "    50: f\"{glove_dir}/glove.6b.50d.txt\",\n",
    "    100: f\"{glove_dir}/glove.6b.100d.txt\",\n",
    "    200: f\"{glove_dir}/glove.6b.200d.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb29ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    \n",
    "\t\"\"\"\n",
    "\tLoads pre-trained GloVe word embeddings from a text file into a Python dictionary.\n",
    "\n",
    "\tArgs:\n",
    "\t\tpath (str): Path to the GloVe `.txt` file containing word vectors.\n",
    "\n",
    "\tReturns:\n",
    "\t\tdict: A dictionary mapping each word (str) to its corresponding embedding vector (numpy.ndarray).\n",
    "\t\"\"\"\n",
    "\n",
    "\tembeddings_index = {}\n",
    "\twith open(path, encoding = \"utf8\") as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tvalues = line.split()\n",
    "\t\t\tword = values[0]\n",
    "\t\t\tvector = np.asarray(values[1:], dtype = \"float32\")\n",
    "\t\t\tembeddings_index[word] = vector\n",
    "\tprint(f\"Loaded {len(embeddings_index)} embeddings from {path}\")\n",
    "\treturn embeddings_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix_glove(embeddings_index, tokenizer, embedding_dimension):\n",
    "    \n",
    "\t\"\"\"\n",
    "\tBuilds an embedding matrix using pre-trained GloVe embeddings for a given tokenizer vocabulary.\n",
    "\n",
    "\tArgs:\n",
    "\t\tembeddings_index (dict): A dictionary mapping words to their GloVe embedding vectors, \n",
    "\t\t\ttypically loaded using `load_glove_embeddings`.\n",
    "\t\ttokenizer (Tokenizer): A fitted Keras Tokenizer containing the vocabulary from the training dataset.\n",
    "\t\tembedding_dimension (int): The dimensionality of the GloVe vectors being used (e.g., 50, 100, 200).\n",
    "\n",
    "\tReturns:\n",
    "\t\tnumpy.ndarray: A 2D NumPy array of shape `(vocabulary_size, embedding_dimension)` where each \n",
    "\t\trow corresponds to a word in the tokenizer's vocabulary. Words not found in the GloVe \n",
    "\t\tembeddings are represented by zero vectors.\n",
    "\t\"\"\"\n",
    "\t\t\n",
    "\tvocabulary_size = len(tokenizer.word_index) + 1\n",
    "\tmatrix = np.zeros((vocabulary_size, embedding_dimension))\n",
    "\tfor word, i in tokenizer.word_index.items():\n",
    "\t\tvector = embeddings_index.get(word)\n",
    "\t\tif vector is not None:\n",
    "\t\t\tmatrix[i] = vector\n",
    "\treturn matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c8b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading GloVe 50D...\n",
      "Loaded 400000 embeddings from ../models/glove.6b/glove.6b.50d.txt\n",
      "Matrix 50D shape: (21023, 50)\n",
      "\n",
      "Loading GloVe 100D...\n",
      "Loaded 400000 embeddings from ../models/glove.6b/glove.6b.100d.txt\n",
      "Matrix 100D shape: (21023, 100)\n",
      "\n",
      "Loading GloVe 200D...\n",
      "Loaded 400000 embeddings from ../models/glove.6b/glove.6b.200d.txt\n",
      "Matrix 200D shape: (21023, 200)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loads pre-trained GloVe embeddings for multiple dimensions and builds corresponding \n",
    "embedding matrices aligned with the tokenizer's vocabulary.\n",
    "\n",
    "For each specified dimensionality (e.g., 50, 100, 200), this code performs the following steps:\n",
    "1. Loads the GloVe embeddings file using `load_glove_embeddings`, creating a dictionary \n",
    "   mapping words to their pre-trained vectors.\n",
    "2. Builds an embedding matrix using `build_embedding_matrix_glove`, aligning each tokenizer \n",
    "   vocabulary word with its corresponding GloVe vector.\n",
    "3. Stores the loaded GloVe embeddings in `glove_models` and the resulting matrices \n",
    "   in `embedding_matrices_glove`.\n",
    "4. Prints the shape of each constructed embedding matrix to confirm successful loading.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "glove_models = {}\n",
    "embedding_matrices_glove = {}\n",
    "\n",
    "for dim, path in model_paths.items():\n",
    "    print(f\"\\nLoading GloVe {dim}D...\")\n",
    "    glove_models[dim] = load_glove_embeddings(path)\n",
    "    embedding_matrices_glove[dim] = build_embedding_matrix_glove(glove_models[dim], tokenizer, dim)\n",
    "    print(f\"Matrix {dim}D shape: {embedding_matrices_glove[dim].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30711a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model A with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6059 - loss: 0.9885 - val_accuracy: 0.6759 - val_loss: 0.9274\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6819 - loss: 0.8758 - val_accuracy: 0.7089 - val_loss: 0.8168\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.7695 - val_accuracy: 0.7696 - val_loss: 0.7227\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7503 - loss: 0.6832 - val_accuracy: 0.7873 - val_loss: 0.6542\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7828 - loss: 0.6205 - val_accuracy: 0.8076 - val_loss: 0.5973\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8008 - loss: 0.5671 - val_accuracy: 0.8076 - val_loss: 0.5503\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.5234 - val_accuracy: 0.8278 - val_loss: 0.5127\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.4900 - val_accuracy: 0.8304 - val_loss: 0.4862\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.4590 - val_accuracy: 0.8329 - val_loss: 0.4557\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8404 - loss: 0.4404 - val_accuracy: 0.8430 - val_loss: 0.4393\n",
      "Training model B with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6107 - loss: 0.9076 - val_accuracy: 0.7899 - val_loss: 0.7045\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7932 - loss: 0.5755 - val_accuracy: 0.8405 - val_loss: 0.4950\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 0.4330 - val_accuracy: 0.8684 - val_loss: 0.3899\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8632 - loss: 0.3617 - val_accuracy: 0.8633 - val_loss: 0.3477\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8713 - loss: 0.3240 - val_accuracy: 0.8937 - val_loss: 0.3058\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8849 - loss: 0.3038 - val_accuracy: 0.8886 - val_loss: 0.2919\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.2856 - val_accuracy: 0.8835 - val_loss: 0.2808\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8952 - loss: 0.2780 - val_accuracy: 0.8658 - val_loss: 0.3181\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8963 - loss: 0.2569 - val_accuracy: 0.8962 - val_loss: 0.2560\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9045 - loss: 0.2459 - val_accuracy: 0.8861 - val_loss: 0.2502\n",
      "Training model C with embedding 50D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6325 - loss: 0.8289 - val_accuracy: 0.8177 - val_loss: 0.5143\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9674 - loss: 0.1259 - val_accuracy: 0.8076 - val_loss: 0.5318\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9978 - loss: 0.0171 - val_accuracy: 0.8051 - val_loss: 0.6342\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7975 - val_loss: 0.5985\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8051 - val_loss: 0.6286\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 9.8856e-04 - val_accuracy: 0.8051 - val_loss: 0.6469\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.4802e-04 - val_accuracy: 0.8101 - val_loss: 0.6666\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 4.8248e-04 - val_accuracy: 0.8076 - val_loss: 0.6799\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.7258e-04 - val_accuracy: 0.8101 - val_loss: 0.6964\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.9539e-04 - val_accuracy: 0.8076 - val_loss: 0.7064\n",
      "Training model A with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5537 - loss: 1.0173 - val_accuracy: 0.6658 - val_loss: 0.9417\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6900 - loss: 0.8738 - val_accuracy: 0.7468 - val_loss: 0.8072\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7562 - loss: 0.7425 - val_accuracy: 0.7646 - val_loss: 0.6896\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7986 - loss: 0.6387 - val_accuracy: 0.7949 - val_loss: 0.6023\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8241 - loss: 0.5572 - val_accuracy: 0.8253 - val_loss: 0.5390\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8328 - loss: 0.5006 - val_accuracy: 0.8430 - val_loss: 0.4823\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.4496 - val_accuracy: 0.8506 - val_loss: 0.4435\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8540 - loss: 0.4130 - val_accuracy: 0.8532 - val_loss: 0.4102\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8681 - loss: 0.3840 - val_accuracy: 0.8658 - val_loss: 0.3879\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8735 - loss: 0.3598 - val_accuracy: 0.8709 - val_loss: 0.3682\n",
      "Training model B with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6547 - loss: 0.8585 - val_accuracy: 0.7418 - val_loss: 0.6665\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8154 - loss: 0.5267 - val_accuracy: 0.8506 - val_loss: 0.4442\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8610 - loss: 0.3844 - val_accuracy: 0.8633 - val_loss: 0.3618\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8789 - loss: 0.3224 - val_accuracy: 0.8734 - val_loss: 0.3235\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8903 - loss: 0.2834 - val_accuracy: 0.8835 - val_loss: 0.2670\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9088 - loss: 0.2537 - val_accuracy: 0.8937 - val_loss: 0.2664\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2410 - val_accuracy: 0.9013 - val_loss: 0.2350\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9088 - loss: 0.2342 - val_accuracy: 0.9038 - val_loss: 0.2302\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9235 - loss: 0.2072 - val_accuracy: 0.9038 - val_loss: 0.2089\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9256 - loss: 0.2001 - val_accuracy: 0.9089 - val_loss: 0.2361\n",
      "Training model C with embedding 100D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.6645 - loss: 0.8142 - val_accuracy: 0.7873 - val_loss: 0.4705\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9940 - loss: 0.0519 - val_accuracy: 0.8228 - val_loss: 0.4402\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8304 - val_loss: 0.4806\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8329 - val_loss: 0.4976\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 9.4908e-04 - val_accuracy: 0.8304 - val_loss: 0.5215\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.3775e-04 - val_accuracy: 0.8329 - val_loss: 0.5279\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4704e-04 - val_accuracy: 0.8253 - val_loss: 0.5422\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.9416e-04 - val_accuracy: 0.8304 - val_loss: 0.5553\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.0586e-04 - val_accuracy: 0.8253 - val_loss: 0.5736\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4972e-04 - val_accuracy: 0.8278 - val_loss: 0.5810\n",
      "Training model A with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5407 - loss: 0.9884 - val_accuracy: 0.6987 - val_loss: 0.8807\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7269 - loss: 0.7920 - val_accuracy: 0.7873 - val_loss: 0.7008\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8154 - loss: 0.6228 - val_accuracy: 0.8354 - val_loss: 0.5634\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8507 - loss: 0.5039 - val_accuracy: 0.8481 - val_loss: 0.4716\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8686 - loss: 0.4230 - val_accuracy: 0.8658 - val_loss: 0.4066\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8893 - loss: 0.3679 - val_accuracy: 0.8684 - val_loss: 0.3628\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3260 - val_accuracy: 0.8911 - val_loss: 0.3291\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9001 - loss: 0.2962 - val_accuracy: 0.8962 - val_loss: 0.3037\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.2725 - val_accuracy: 0.9013 - val_loss: 0.2816\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2507 - val_accuracy: 0.9063 - val_loss: 0.2682\n",
      "Training model B with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7009 - loss: 0.7718 - val_accuracy: 0.8456 - val_loss: 0.5107\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8594 - loss: 0.3971 - val_accuracy: 0.8785 - val_loss: 0.3435\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9050 - loss: 0.2646 - val_accuracy: 0.9089 - val_loss: 0.2387\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9218 - loss: 0.2155 - val_accuracy: 0.9316 - val_loss: 0.1988\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1713 - val_accuracy: 0.9392 - val_loss: 0.1625\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9381 - loss: 0.1697 - val_accuracy: 0.9139 - val_loss: 0.1997\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.1294 - val_accuracy: 0.9468 - val_loss: 0.1458\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9582 - loss: 0.1163 - val_accuracy: 0.9342 - val_loss: 0.1426\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.1132 - val_accuracy: 0.9443 - val_loss: 0.1265\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9582 - loss: 0.1058 - val_accuracy: 0.9595 - val_loss: 0.1120\n",
      "Training model C with embedding 200D\n",
      "Epoch 1/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.6661 - loss: 0.9661 - val_accuracy: 0.8051 - val_loss: 0.4573\n",
      "Epoch 2/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9913 - loss: 0.0466 - val_accuracy: 0.8127 - val_loss: 0.4356\n",
      "Epoch 3/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8405 - val_loss: 0.4450\n",
      "Epoch 4/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8380 - val_loss: 0.4557\n",
      "Epoch 5/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 6.1716e-04 - val_accuracy: 0.8380 - val_loss: 0.4752\n",
      "Epoch 6/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 2.8118e-04 - val_accuracy: 0.8430 - val_loss: 0.4889\n",
      "Epoch 7/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 1.5690e-04 - val_accuracy: 0.8380 - val_loss: 0.5163\n",
      "Epoch 8/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.9626e-05 - val_accuracy: 0.8354 - val_loss: 0.5315\n",
      "Epoch 9/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 6.8406e-05 - val_accuracy: 0.8380 - val_loss: 0.5448\n",
      "Epoch 10/10\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 4.8462e-05 - val_accuracy: 0.8380 - val_loss: 0.5537\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code block trains and evaluates multiple text classification models using different \n",
    "embedding dimensions and neural network architectures. For each combination of embedding \n",
    "matrix and architecture, it builds a Keras model, trains it on the training data, validates \n",
    "it on a separate validation set, and evaluates it on the test set.\n",
    "\n",
    "The workflow proceeds as follows:\n",
    "1. Iterate over all available embedding matrices, each corresponding to a specific \n",
    "   embedding dimensionality (e.g., 50D, 100D, 200D).\n",
    "2. For each embedding dimension, iterate over all predefined model architectures (A, B, C), \n",
    "   where each architecture defines a different neural network structure.\n",
    "3. Build an embedding layer from the current embedding matrix and pass it to the model \n",
    "   construction function.\n",
    "4. Compile the model using the Adam optimizer and sparse categorical cross-entropy loss.\n",
    "5. Train the model for 10 epochs on the training data, using the validation set for \n",
    "   monitoring performance.\n",
    "6. Generate predictions on the test set and compute evaluation metrics: accuracy, \n",
    "   precision (macro-averaged), and recall (macro-averaged).\n",
    "7. Store the performance metrics for each (architecture, embedding dimension) pair \n",
    "   in the `results` dictionary for later comparison.\n",
    "\n",
    "The `results` dictionary uses keys in the format \"{ARCH}_{DIM}D\" (e.g., \"A_50D\") and maps \n",
    "them to metric dictionaries with the following structure:\n",
    "{\n",
    "    \"accuracy\": float,\n",
    "    \"precision\": float,\n",
    "    \"recall\": float\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for embedding_dimension, embedding_matrix in embedding_matrices_glove.items():\n",
    "    for arch_name, build_fn in architectures.items():\n",
    "        print(f\"Training model {arch_name} with embedding {embedding_dimension}D\")\n",
    "\n",
    "        embedding_layer = make_embedding_layer(embedding_matrix)\n",
    "        model = build_fn(embedding_layer)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = Adam(),\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train_sequences, y_train,\n",
    "            validation_data = (X_validation_sequences, y_validation),\n",
    "            epochs = 10,\n",
    "            batch_size = 32,\n",
    "            verbose = 1\n",
    "        )\n",
    "\n",
    "        y_pred_probs = model.predict(X_test_sequences, verbose = 0)\n",
    "        y_pred = np.argmax(y_pred_probs, axis = 1)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
    "        recall = recall_score(y_test, y_pred, average = 'macro', zero_division = 0)\n",
    "\n",
    "        key = f\"{arch_name}_{embedding_dimension}D\"\n",
    "        results[key] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b68b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       accuracy precision recall\n",
      "A_50D     0.830     0.827  0.820\n",
      "B_50D     0.871     0.874  0.858\n",
      "C_50D     0.800     0.807  0.772\n",
      "A_100D    0.858     0.856  0.854\n",
      "B_100D    0.891     0.924  0.860\n",
      "C_100D    0.828     0.837  0.801\n",
      "A_200D    0.896     0.897  0.889\n",
      "B_200D    0.934     0.932  0.928\n",
      "C_200D    0.853     0.861  0.829\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code block converts the collected training and evaluation results into a \n",
    "readable tabular format using a pandas DataFrame.\n",
    "\n",
    "The resulting table allows quick inspection of which architecture–embedding combination \n",
    "performed best across the various metrics.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results).T \n",
    "\n",
    "df_formatted = df.map(lambda x: f\"{x:.3f}\")\n",
    "\n",
    "print(df_formatted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
